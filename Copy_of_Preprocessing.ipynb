{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuzhattttt/braintumor/blob/main/Copy_of_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RXvLJ53w6IqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf9c033-0477-47a7-cda0-162e4a9dc76c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PpSYiS908uQ8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RjfPdAX6xn0F"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_directory = '/content/gdrive/MyDrive/Amar dataset/dataset/Training'\n",
        "test_directory = '/content/gdrive/MyDrive/Amar dataset/dataset/Testing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lPR2KR2rxno6"
      },
      "outputs": [],
      "source": [
        "image_size = (128, 128)\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UhsdO0Gc0_sH"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(directory, images_list, labels_list):\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_directory = os.path.join(directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_directory):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                image_path = os.path.join(class_directory, filename)\n",
        "                image = Image.open(image_path).convert(\"RGB\")\n",
        "                image = image.resize(image_size, Image.LANCZOS)\n",
        "                images_list.append(image)\n",
        "                labels_list.append(class_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DbPXRf6g1bma"
      },
      "outputs": [],
      "source": [
        "load_and_preprocess_images(train_directory, train_images, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vu1enbJ02OEk"
      },
      "outputs": [],
      "source": [
        "load_and_preprocess_images(test_directory, test_images, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3nuhfHQx2nk-"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_encoded_labels = label_encoder.fit_transform(train_labels)\n",
        "test_encoded_labels = label_encoder.transform(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9auYL7pX3-rV"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([np.array(img) for img in train_images])\n",
        "y_train = np.array(train_encoded_labels)\n",
        "X_test = np.array([np.array(img) for img in test_images])\n",
        "y_test = np.array(test_encoded_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CePHIht6BbHJ",
        "outputId": "84923a56-553b-47b5-c8e8-5f4ada3087c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (5722, 128, 128, 3)\n",
            "y_train shape: (5722,)\n",
            "X_test shape: (1311, 128, 128, 3)\n",
            "y_test shape: (1311,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-L2-emcyv3y0"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "import time\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7JMZ6C6XwEAN"
      },
      "outputs": [],
      "source": [
        "# model_CNN = tf.keras.Sequential()\n",
        "# model_CNN.add(layers.InputLayer(input_shape=(128, 128, 3)))\n",
        "\n",
        "# model_CNN.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
        "# model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_CNN.add(layers.BatchNormalization())\n",
        "# model_CNN.add(layers.Dropout(0.25))\n",
        "\n",
        "# model_CNN.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
        "# model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_CNN.add(layers.BatchNormalization())\n",
        "# model_CNN.add(layers.Dropout(0.25))\n",
        "\n",
        "# model_CNN.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "# model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_CNN.add(layers.BatchNormalization())\n",
        "# model_CNN.add(layers.Dropout(0.25))\n",
        "\n",
        "# model_CNN.add(layers.Conv2D(256, (2, 2), activation='relu'))\n",
        "# model_CNN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# model_CNN.add(layers.BatchNormalization())\n",
        "# model_CNN.add(layers.Dropout(0.25))\n",
        "\n",
        "# model_CNN.add(layers.Flatten())\n",
        "# model_CNN.add(layers.Dense(2048, activation='relu'))\n",
        "# model_CNN.add(layers.Dropout(0.25))\n",
        "# model_CNN.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "# optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
        "# model_CNN.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "class VGG16:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model_CNN = Sequential()\n",
        "        model_CNN.add(Conv2D(input_shape=shape,filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model_CNN.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model_CNN.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model_CNN.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model_CNN.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "        model_CNN.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model_CNN.add(Flatten())\n",
        "        model_CNN.add(Dense(units=4096,activation=\"relu\"))\n",
        "        model_CNN.add(Dense(units=4096,activation=\"relu\"))\n",
        "        model_CNN.add(Dense(units=classes, activation=\"softmax\"))\n",
        "        return model_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIWvCe7_lWrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3a1ac0-ee81-4bfd-c0fb-bddbfcaf20b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 2/90 [..............................] - ETA: 27:20 - loss: 74.5393 - accuracy: 0.2422"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "num_classes=4\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes)\n",
        "# Create an instance of the VGG16 model\n",
        "vgg16_model_CNN = VGG16.build(shape=(128, 128, 3), classes=num_classes)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "vgg16_model_CNN.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "history_CNN = vgg16_model_CNN.fit(\n",
        "    X_train, y_train_encoded,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = vgg16_model_CNN.evaluate(X_test, y_test_encoded)\n",
        "print(f'Test accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D2k3WMlR8t6"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsF_zm0dR-JT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_CNN.history[\"loss\"], c=\"red\")\n",
        "plt.plot(history_CNN.history[\"accuracy\"], c=\"green\")\n",
        "plt.title(\"Loss and Accuracy in the CNN Model\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(['loss', 'accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmt8_Oo75pIv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.mobilenet_v2 import decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "Mob = MobileNetV2(weights='imagenet', include_top=True)\n",
        "Mob.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNjKwDoX5qXs"
      },
      "outputs": [],
      "source": [
        "# make a reference to MobileNets's input layer\n",
        "inp = Mob.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in MobileNets, and make a reference to it\n",
        "out = new_classification_layer(Mob.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_new = Model(inp, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orLF84_g57l6"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_new.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_new.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_new.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-4Wt-eL6RtU"
      },
      "outputs": [],
      "source": [
        "history2 = model_new.fit(x_train, y_train,\n",
        "                         batch_size=64,\n",
        "                         epochs=50,\n",
        "                         validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z1zWg-c6kqv"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history2.history[\"loss\"])\n",
        "ax.plot(history2.history[\"val_loss\"])\n",
        "ax.set_title(\"loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history2.history[\"accuracy\"])\n",
        "ax2.plot(history2.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60xiYG1B6lKQ"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf5oIeRD6p9d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.nasnet import decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "nas = NASNetMobile(weights='imagenet', include_top=True)\n",
        "nas.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlx-dawQ6tDx"
      },
      "outputs": [],
      "source": [
        "# make a reference to VGG's input layer\n",
        "inp = nas.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
        "out = new_classification_layer(nas.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_nas = Model(inp, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q5G5qVq63Mw"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_nas.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_nas.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_nas.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_nas.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtfyV1b263_1"
      },
      "outputs": [],
      "source": [
        "history3 = model_nas.fit(x_train, y_train,\n",
        "                         batch_size=64,\n",
        "                         epochs=50,\n",
        "                         validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxmvdrC27Gzu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history3.history[\"loss\"])\n",
        "ax.plot(history3.history[\"val_loss\"])\n",
        "ax.set_title(\"loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history3.history[\"accuracy\"])\n",
        "ax2.plot(history3.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"validation accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrTBqkbD63wO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "vgg = VGG16(weights='imagenet', include_top=True)\n",
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwpK9FaW7LNK"
      },
      "outputs": [],
      "source": [
        "# make a reference to VGG's input layer\n",
        "inp = vgg.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
        "out = new_classification_layer(vgg.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_vgg = Model(inp, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krcc9gaY7LJx"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_vgg.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_vgg.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_vgg.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAuWKJJ17LHb"
      },
      "outputs": [],
      "source": [
        "history4 = model_vgg.fit(x_train, y_train,\n",
        "                         batch_size=64,\n",
        "                         epochs=50,\n",
        "                         validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o8iouyM7LE2"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history4.history[\"loss\"])\n",
        "ax.plot(history4.history[\"val_loss\"])\n",
        "\n",
        "ax.set_title(\"loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history4.history[\"accuracy\"])\n",
        "ax2.plot(history4.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnYVlcoM7LCJ"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_vgg.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f8wE4YP7K8K"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "rn = ResNet50(weights='imagenet', include_top=True)\n",
        "rn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgcBAVia7ja6"
      },
      "outputs": [],
      "source": [
        "# make a reference to VGG's input layer\n",
        "inp = rn.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
        "out = new_classification_layer(rn.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_rn = Model(inp, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMRuoIr07jHH"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_rn.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_rn.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_rn.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_rn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0JACgXL7q6x"
      },
      "outputs": [],
      "source": [
        "history5 = model_rn.fit(x_train, y_train,\n",
        "                         batch_size=256,\n",
        "                         epochs=60,\n",
        "                         validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayI7anYj7qyc"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history5.history[\"loss\"])\n",
        "ax.plot(history5.history[\"val_loss\"])\n",
        "ax.set_title(\"loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history5.history[\"accuracy\"])\n",
        "ax2.plot(history5.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om_RAzpu710K"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_rn.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOuG1svz76WH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.densenet import decode_predictions\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "den = DenseNet121(weights='imagenet', include_top=True)\n",
        "den.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRxmKy9E76F9"
      },
      "outputs": [],
      "source": [
        "# make a reference to MobileNets's input layer\n",
        "inp = den.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in MobileNets, and make a reference to it\n",
        "out = new_classification_layer(den.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_den = Model(inp, out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu-UYO8b8HZn"
      },
      "outputs": [],
      "source": [
        "# make all layers untrainable by freezing weights (except for last layer)\n",
        "for l, layer in enumerate(model_den.layers[:-1]):\n",
        "    layer.trainable = False\n",
        "\n",
        "# ensure the last layer is trainable/not frozen\n",
        "for l, layer in enumerate(model_den.layers[-1:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_den.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_den.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99L7BToM8Rej"
      },
      "outputs": [],
      "source": [
        "history6 = model_den.fit(x_train, y_train,\n",
        "                         batch_size=64,\n",
        "                         epochs=50,\n",
        "                         validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG2m1Vun8Svn"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20,4))\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(history6.history[\"loss\"])\n",
        "ax.plot(history6.history[\"val_loss\"])\n",
        "ax.set_title(\"loss\")\n",
        "ax.set_xlabel(\"epochs\")\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history6.history[\"accuracy\"])\n",
        "ax2.plot(history6.history[\"val_accuracy\"])\n",
        "ax2.set_title(\"accuracy\")\n",
        "ax2.set_xlabel(\"epochs\")\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CyTG8sd8nrg"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model_den.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5VMLP-a8SsO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNWs7VHv8SoZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1kuf9ShzAwd"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert categorical labels to one-hot encoded format\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZHYrRK-xm0c"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e6DqEhzzdtx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "num_classes=4\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes)\n",
        "# Create an instance of the VGG16 model\n",
        "vgg16_model_CNN = VGG16.build(shape=(128, 128, 3), classes=num_classes)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "vgg16_model_CNN.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "history_CNN = vgg16_model_CNN.fit(\n",
        "    X_train, y_train_encoded,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = vgg16_model_CNN.evaluate(X_test, y_test_encoded)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCyBuVLTRc+cOpuw5NBb6K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}